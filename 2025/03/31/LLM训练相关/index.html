<!DOCTYPE html>


  <html class="light page-post">


<head>
  <meta charset="utf-8">
  
  <title>LLM训练相关 | Hexo</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="reality,前端,算法，机器学习，AI，日常记录" />
  

  <meta name="description" content="大模型显存占用（以 1B 参数为例）1B&#x3D;100031B&#x3D;1000^31B&#x3D;10003 参数量 1GB&#x3D;102431GB&#x3D;1024^31GB&#x3D;10243 Bytes  全参数训练（混合精度） 模型参数(FP16)：2GB 梯度(FP16)：2GB 优化器状态（Adam 优化器 FP32）：2∗4GB+4GB&#x3D;12GB2*4GB+4GB&#x3D;12GB2∗4GB+4GB&#x3D;12GB(因为 FP16 精度不够">
<meta property="og:type" content="article">
<meta property="og:title" content="LLM训练相关">
<meta property="og:url" content="https://zyyy9.github.io/2025/03/31/LLM%E8%AE%AD%E7%BB%83%E7%9B%B8%E5%85%B3/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="大模型显存占用（以 1B 参数为例）1B&#x3D;100031B&#x3D;1000^31B&#x3D;10003 参数量 1GB&#x3D;102431GB&#x3D;1024^31GB&#x3D;10243 Bytes  全参数训练（混合精度） 模型参数(FP16)：2GB 梯度(FP16)：2GB 优化器状态（Adam 优化器 FP32）：2∗4GB+4GB&#x3D;12GB2*4GB+4GB&#x3D;12GB2∗4GB+4GB&#x3D;12GB(因为 FP16 精度不够">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-03-31T05:55:23.000Z">
<meta property="article:modified_time" content="2025-04-01T15:18:03.645Z">
<meta property="article:author" content="钟宇">
<meta name="twitter:card" content="summary">

  

  
    <link rel="icon" href="https://dogefs.s3.ladydaily.com/~/source/wallhaven/small/e7/e7kejr.jpg?w=400&h=200&fmt=webp">
  

  <link href="/css/styles.css?v=c114cbeddx" rel="stylesheet">


  
    
<link rel="stylesheet" href="/css/personal-style.css">

  

  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-38189205-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


  
  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?57e94d016e201fba3603a8a2b0263af0";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>


  
  <script type="text/javascript">
	(function(){
	    var bp = document.createElement('script');
	    var curProtocol = window.location.protocol.split(':')[0];
	    if (curProtocol === 'https') {
	        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
	    }
	    else {
	        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
	    }
	    var s = document.getElementsByTagName("script")[0];
	    s.parentNode.insertBefore(bp, s);
	})();
  </script>



  

<!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" integrity="sha512-fHwaWebuwA7NSF5Qg/af4UeDx9XqUpYpOGgubo3yWu+b2IQR4UeQwbb42Ti7gVAjNtVoI/I9TEoYeu9omwcC6g==" crossorigin="anonymous" referrerpolicy="no-referrer" /><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head>

<body>


  
    <span id="toolbox-mobile" class="toolbox-mobile">Home</span>
  

  <div class="post-header CENTER">
   
  <div class="toolbox">
    <a class="toolbox-entry" href="/">
      <span class="toolbox-entry-text">Home</span>
      <i class="icon-angle-down"></i>
      <i class="icon-home"></i>
    </a>
    <ul class="list-toolbox">
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/archives/"
            rel="noopener noreferrer"
            target="_self"
            >
            博客
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/category/"
            rel="noopener noreferrer"
            target="_self"
            >
            分类
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/link/"
            rel="noopener noreferrer"
            target="_self"
            >
            友链
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/about/"
            rel="noopener noreferrer"
            target="_self"
            >
            关于
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/search/"
            rel="noopener noreferrer"
            target="_self"
            >
            搜索
          </a>
        </li>
      
    </ul>
  </div>


</div>


  <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%EF%BC%88%E4%BB%A5-1B-%E5%8F%82%E6%95%B0%E4%B8%BA%E4%BE%8B%EF%BC%89"><span class="toc-text">大模型显存占用（以 1B 参数为例）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E5%8F%82%E6%95%B0%E8%AE%AD%E7%BB%83%EF%BC%88%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%EF%BC%89"><span class="toc-text">全参数训练（混合精度）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LoRA-%E5%BE%AE%E8%B0%83%EF%BC%88%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%EF%BC%89"><span class="toc-text">LoRA 微调（混合精度）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gradient-checkpoints"><span class="toc-text">gradient checkpoints</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%92%A1-%E4%B8%BE%E4%B8%AA%E4%BE%8B%E5%AD%90%EF%BC%9A"><span class="toc-text">💡 举个例子：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-text">总结</span></a></li></ol></li></ol>
  </div>



<div class="content content-post CENTER">
   <article id="post-LLM训练相关" class="article article-type-post" itemprop="blogPost">
  <header class="article-header">
    <h1 class="post-title">LLM训练相关</h1>

    <div class="article-meta">
      <span>
        <i class="icon-calendar"></i>
        <span>2025.03.31</span>
      </span>

      
        <span class="article-author">
          <i class="icon-user"></i>
          <span>钟宇</span>
        </span>
      

      
  <span class="article-category">
    <i class="icon-list"></i>
    <a class="article-category-link" href="/categories/LLM%E5%9F%BA%E7%A1%80/">LLM基础</a>
  </span>



      

      
      
    </div>
  </header>

  <div class="article-content">
    
      <h2 id="大模型显存占用（以-1B-参数为例）"><a href="#大模型显存占用（以-1B-参数为例）" class="headerlink" title="大模型显存占用（以 1B 参数为例）"></a>大模型显存占用（以 1B 参数为例）</h2><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>B</mi><mo>=</mo><msup><mn>1000</mn><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">1B=1000^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">1</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">100</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span> 参数量
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>G</mi><mi>B</mi><mo>=</mo><msup><mn>1024</mn><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">1GB=1024^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">1</span><span class="mord mathnormal" style="margin-right:0.05017em;">GB</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">102</span><span class="mord"><span class="mord">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span> Bytes

<h3 id="全参数训练（混合精度）"><a href="#全参数训练（混合精度）" class="headerlink" title="全参数训练（混合精度）"></a>全参数训练（混合精度）</h3><ol>
<li>模型参数(FP16)：2GB</li>
<li>梯度(FP16)：2GB</li>
<li>优化器状态（Adam 优化器 FP32）：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>∗</mo><mn>4</mn><mi>G</mi><mi>B</mi><mo>+</mo><mn>4</mn><mi>G</mi><mi>B</mi><mo>=</mo><mn>12</mn><mi>G</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">2*4GB+4GB=12GB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mord mathnormal" style="margin-right:0.05017em;">GB</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">4</span><span class="mord mathnormal" style="margin-right:0.05017em;">GB</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">12</span><span class="mord mathnormal" style="margin-right:0.05017em;">GB</span></span></span></span><br>(因为 FP16 精度不够，优化器动量+模型参数)</li>
<li>激活值(FP16)：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>∗</mo><mi>b</mi><mo>∗</mo><mi>h</mi><mo>∗</mo><mo stretchy="false">(</mo><mn>34</mn><mo>+</mo><mn>5</mn><mo>∗</mo><mi>a</mi><mo>∗</mo><mi>s</mi><mi mathvariant="normal">/</mi><mi>h</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>L</mi><mi mathvariant="normal">/</mi><mn>1024</mn><mi mathvariant="normal">/</mi><mn>1024</mn><mi mathvariant="normal">/</mi><mn>1024</mn></mrow><annotation encoding="application/x-tex">s*b*h*(34+5*a*s/h)*L/1024/1024/1024</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4653em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">34</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4653em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord">/</span><span class="mord mathnormal">h</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord">/1024/1024/1024</span></span></span></span><br><strong><em>s 是序列长度，b 是 batchsize，h 是隐藏层大小，a 是 attention 头个数，L 是层数</em></strong></li>
</ol>
<h3 id="LoRA-微调（混合精度）"><a href="#LoRA-微调（混合精度）" class="headerlink" title="LoRA 微调（混合精度）"></a>LoRA 微调（混合精度）</h3><ol>
<li>模型参数：2GB+LoRA 参数（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>∗</mo><mn>0.1</mn><mi>G</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">2*0.1GB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">0.1</span><span class="mord mathnormal" style="margin-right:0.05017em;">GB</span></span></span></span>）</li>
<li>梯度：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>∗</mo><mn>0.1</mn><mi>G</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">2*0.1GB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">0.1</span><span class="mord mathnormal" style="margin-right:0.05017em;">GB</span></span></span></span></li>
<li>优化器状态（Adam 优化器 FP32）：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>12</mn><mo>∗</mo><mn>0.1</mn><mi>G</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">12*0.1GB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">12</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">0.1</span><span class="mord mathnormal" style="margin-right:0.05017em;">GB</span></span></span></span></li>
<li>激活值：</li>
</ol>
<h3 id="gradient-checkpoints"><a href="#gradient-checkpoints" class="headerlink" title="gradient checkpoints"></a>gradient checkpoints</h3><p><strong>是的！</strong> 计算机在进行数值运算时，<strong>中间计算结果</strong> <strong>不一定</strong> 会占用显存，具体情况取决于以下几个因素：  </p>
<ol>
<li><p><strong>计算结果是否需要被存储</strong> 🔥  </p>
<ul>
<li><strong>不存储</strong>：如果计算结果只是<strong>临时值</strong>，那么它会被存放在<strong>寄存器（registers）</strong> 或 <strong>缓存（cache）</strong> 里，不会进入显存。  </li>
<li><strong>需要存储</strong>：如果计算结果稍后还要被使用（比如用于反向传播的激活值），就必须存到显存（VRAM）。</li>
</ul>
</li>
<li><p><strong>计算是在 CPU 还是 GPU 上进行</strong> 🖥️🎮  </p>
<ul>
<li><strong>CPU 计算</strong>：临时值通常存在 CPU 的<strong>寄存器</strong> 或 <strong>RAM</strong>，只有必要时才写回到内存。  </li>
<li><strong>GPU 计算</strong>：数值运算通常在<strong>寄存器</strong> 或 <strong>共享内存</strong> 中进行，<strong>只有需要长期存储的值才会进入显存（VRAM）</strong>。</li>
</ul>
</li>
<li><p><strong>是否启用了显存优化策略（如梯度检查点）</strong> 🚀  </p>
<ul>
<li>默认情况下，<strong>所有中间激活值都会存到显存</strong>，以便反向传播计算梯度。  </li>
<li>如果启用 <strong>梯度检查点（Gradient Checkpointing）</strong>，前向传播的激活值<strong>不会存储</strong>，显存占用会减少，但反向传播时要重新计算一次。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="💡-举个例子："><a href="#💡-举个例子：" class="headerlink" title="💡 举个例子："></a><strong>💡 举个例子：</strong></h3><p>假设我们执行如下计算：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.tensor([<span class="number">3.0</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = x * <span class="number">2</span>  <span class="comment"># y = 6</span></span><br><span class="line">z = y ** <span class="number">2</span>  <span class="comment"># z = 36</span></span><br></pre></td></tr></table></figure>
<p><strong>情况 1️⃣：普通计算（不会占用显存）</strong></p>
<ul>
<li><code>x * 2</code> 的结果 <code>y=6</code> <strong>可能仅存于寄存器</strong>（临时计算结果）。</li>
<li><code>y ** 2</code> 的计算完成后，<code>y=6</code> <strong>不再被需要</strong>，它的值会被丢弃。</li>
</ul>
<p><strong>情况 2️⃣：需要反向传播（占用显存）</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z.backward()  <span class="comment"># 计算 dL/dx</span></span><br></pre></td></tr></table></figure>
<ul>
<li>由于 <code>z</code> 依赖于 <code>y</code>，而 <code>y</code> 依赖于 <code>x</code>，<strong>PyTorch 需要存储计算图（computation graph）</strong>，这些中间值（如 <code>y=6</code>）就会被<strong>存到显存</strong>。</li>
</ul>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>✅ <strong>纯计算（如 <code>a + b</code>）的中间结果</strong>通常不会直接占用显存，因为它们只在寄存器&#x2F;缓存中短暂存在。<br>✅ <strong>只有当计算结果需要被存储（如激活值用于反向传播）时，才会占用显存！</strong><br>✅ <strong>显存优化（如梯度检查点）可以减少存储的中间值，但计算量会增加</strong>。  </p>
<p>如果你的显存不够，可以考虑 <strong>梯度检查点（gradient_checkpointing_enable()）</strong> 或者 <strong>减少 batch size</strong>！ 🚀</p>

    
  </div>

</article>


   



</div>


  <a id="backTop" class="back-top">
    <i class="icon-angle-up"></i>
  </a>




  <div class="modal" id="modal">
  <span id="cover" class="cover hide"></span>
  <div id="modal-dialog" class="modal-dialog hide-dialog">
    <div class="modal-header">
      <span id="close" class="btn-close">关闭</span>
    </div>
    <hr>
    <div class="modal-body">
      <ul class="list-toolbox">
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/archives/"
              rel="noopener noreferrer"
              target="_self"
              >
              博客
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/category/"
              rel="noopener noreferrer"
              target="_self"
              >
              分类
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/link/"
              rel="noopener noreferrer"
              target="_self"
              >
              友链
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/about/"
              rel="noopener noreferrer"
              target="_self"
              >
              关于
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/search/"
              rel="noopener noreferrer"
              target="_self"
              >
              搜索
            </a>
          </li>
        
      </ul>

    </div>
  </div>
</div>



  <script type="text/javascript">
  function loadScript(url, callback) {
    var script = document.createElement('script')
    script.type = 'text/javascript';

    if (script.readyState) { //IE
      script.onreadystatechange = function() {
        if (script.readyState == 'loaded' ||
          script.readyState == 'complete') {
          script.onreadystatechange = null;
          callback();
        }
      };
    } else { //Others
      script.onload = function() {
        callback();
      };
    }

    script.src = url;
    document.getElementsByTagName('head')[0].appendChild(script);
  }

  window.onload = function() {
    loadScript('/js/bundle.js?235683', function() {
      // load success
    });
  }
</script>

</body>
</html>
